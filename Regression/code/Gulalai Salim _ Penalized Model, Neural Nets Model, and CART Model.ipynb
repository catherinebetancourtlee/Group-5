{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression - Penalized Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Table like structure\n",
    "import pandas as pd\n",
    "\n",
    "#numerical computation\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "#scikit learn\n",
    "#Ridge regression model\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "#Simple decision tree\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from math import sqrt\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#import pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "#Used for normalizing the data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#For generating graphs\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S.No</th>\n",
       "      <th>Left-Lateral-Ventricle</th>\n",
       "      <th>Left-Inf-Lat-Vent</th>\n",
       "      <th>Left-Cerebellum-White-Matter</th>\n",
       "      <th>Left-Cerebellum-Cortex</th>\n",
       "      <th>Left-Thalamus</th>\n",
       "      <th>Left-Caudate</th>\n",
       "      <th>Left-Putamen</th>\n",
       "      <th>Left-Pallidum</th>\n",
       "      <th>3rd-Ventricle</th>\n",
       "      <th>...</th>\n",
       "      <th>rh_supramarginal_thickness</th>\n",
       "      <th>rh_frontalpole_thickness</th>\n",
       "      <th>rh_temporalpole_thickness</th>\n",
       "      <th>rh_transversetemporal_thickness</th>\n",
       "      <th>rh_insula_thickness</th>\n",
       "      <th>rh_MeanThickness_thickness</th>\n",
       "      <th>BrainSegVolNotVent.2</th>\n",
       "      <th>eTIV.1</th>\n",
       "      <th>Age</th>\n",
       "      <th>dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>22916.9</td>\n",
       "      <td>982.7</td>\n",
       "      <td>15196.7</td>\n",
       "      <td>55796.4</td>\n",
       "      <td>6855.5</td>\n",
       "      <td>2956.4</td>\n",
       "      <td>4240.7</td>\n",
       "      <td>2223.9</td>\n",
       "      <td>2034.4</td>\n",
       "      <td>...</td>\n",
       "      <td>2.408</td>\n",
       "      <td>2.629</td>\n",
       "      <td>3.519</td>\n",
       "      <td>2.009</td>\n",
       "      <td>2.825</td>\n",
       "      <td>2.33635</td>\n",
       "      <td>1093846</td>\n",
       "      <td>1619602.965</td>\n",
       "      <td>85</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>22953.2</td>\n",
       "      <td>984.5</td>\n",
       "      <td>15289.7</td>\n",
       "      <td>55778.6</td>\n",
       "      <td>6835.1</td>\n",
       "      <td>3064.2</td>\n",
       "      <td>4498.6</td>\n",
       "      <td>2354.1</td>\n",
       "      <td>1927.1</td>\n",
       "      <td>...</td>\n",
       "      <td>2.417</td>\n",
       "      <td>2.640</td>\n",
       "      <td>3.488</td>\n",
       "      <td>2.111</td>\n",
       "      <td>2.720</td>\n",
       "      <td>2.34202</td>\n",
       "      <td>1099876</td>\n",
       "      <td>1624755.130</td>\n",
       "      <td>85</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>23320.4</td>\n",
       "      <td>1062.1</td>\n",
       "      <td>15382.1</td>\n",
       "      <td>55551.2</td>\n",
       "      <td>7566.0</td>\n",
       "      <td>3231.7</td>\n",
       "      <td>4456.2</td>\n",
       "      <td>1995.4</td>\n",
       "      <td>2064.7</td>\n",
       "      <td>...</td>\n",
       "      <td>2.374</td>\n",
       "      <td>2.601</td>\n",
       "      <td>3.342</td>\n",
       "      <td>2.146</td>\n",
       "      <td>2.684</td>\n",
       "      <td>2.31982</td>\n",
       "      <td>1097999</td>\n",
       "      <td>1622609.518</td>\n",
       "      <td>86</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>24360.0</td>\n",
       "      <td>1000.5</td>\n",
       "      <td>14805.4</td>\n",
       "      <td>54041.8</td>\n",
       "      <td>8004.6</td>\n",
       "      <td>3137.3</td>\n",
       "      <td>4262.2</td>\n",
       "      <td>1983.4</td>\n",
       "      <td>2017.7</td>\n",
       "      <td>...</td>\n",
       "      <td>2.366</td>\n",
       "      <td>2.639</td>\n",
       "      <td>3.361</td>\n",
       "      <td>2.056</td>\n",
       "      <td>2.700</td>\n",
       "      <td>2.29215</td>\n",
       "      <td>1070117</td>\n",
       "      <td>1583854.236</td>\n",
       "      <td>87</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>25769.4</td>\n",
       "      <td>1124.4</td>\n",
       "      <td>16331.1</td>\n",
       "      <td>54108.6</td>\n",
       "      <td>6677.4</td>\n",
       "      <td>2964.4</td>\n",
       "      <td>4204.6</td>\n",
       "      <td>2409.7</td>\n",
       "      <td>2251.8</td>\n",
       "      <td>...</td>\n",
       "      <td>2.381</td>\n",
       "      <td>2.555</td>\n",
       "      <td>3.450</td>\n",
       "      <td>2.052</td>\n",
       "      <td>2.574</td>\n",
       "      <td>2.30397</td>\n",
       "      <td>1075926</td>\n",
       "      <td>1617375.362</td>\n",
       "      <td>89</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 141 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   S.No  Left-Lateral-Ventricle  Left-Inf-Lat-Vent  \\\n",
       "0     1                 22916.9              982.7   \n",
       "1     2                 22953.2              984.5   \n",
       "2     3                 23320.4             1062.1   \n",
       "3     4                 24360.0             1000.5   \n",
       "4     5                 25769.4             1124.4   \n",
       "\n",
       "   Left-Cerebellum-White-Matter  Left-Cerebellum-Cortex  Left-Thalamus  \\\n",
       "0                       15196.7                 55796.4         6855.5   \n",
       "1                       15289.7                 55778.6         6835.1   \n",
       "2                       15382.1                 55551.2         7566.0   \n",
       "3                       14805.4                 54041.8         8004.6   \n",
       "4                       16331.1                 54108.6         6677.4   \n",
       "\n",
       "   Left-Caudate  Left-Putamen  Left-Pallidum  3rd-Ventricle  ...  \\\n",
       "0        2956.4        4240.7         2223.9         2034.4  ...   \n",
       "1        3064.2        4498.6         2354.1         1927.1  ...   \n",
       "2        3231.7        4456.2         1995.4         2064.7  ...   \n",
       "3        3137.3        4262.2         1983.4         2017.7  ...   \n",
       "4        2964.4        4204.6         2409.7         2251.8  ...   \n",
       "\n",
       "   rh_supramarginal_thickness  rh_frontalpole_thickness  \\\n",
       "0                       2.408                     2.629   \n",
       "1                       2.417                     2.640   \n",
       "2                       2.374                     2.601   \n",
       "3                       2.366                     2.639   \n",
       "4                       2.381                     2.555   \n",
       "\n",
       "   rh_temporalpole_thickness  rh_transversetemporal_thickness  \\\n",
       "0                      3.519                            2.009   \n",
       "1                      3.488                            2.111   \n",
       "2                      3.342                            2.146   \n",
       "3                      3.361                            2.056   \n",
       "4                      3.450                            2.052   \n",
       "\n",
       "   rh_insula_thickness  rh_MeanThickness_thickness  BrainSegVolNotVent.2  \\\n",
       "0                2.825                     2.33635               1093846   \n",
       "1                2.720                     2.34202               1099876   \n",
       "2                2.684                     2.31982               1097999   \n",
       "3                2.700                     2.29215               1070117   \n",
       "4                2.574                     2.30397               1075926   \n",
       "\n",
       "        eTIV.1  Age  dataset  \n",
       "0  1619602.965   85        1  \n",
       "1  1624755.130   85        1  \n",
       "2  1622609.518   86        1  \n",
       "3  1583854.236   87        1  \n",
       "4  1617375.362   89        1  \n",
       "\n",
       "[5 rows x 141 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset and show its first 5 rows\n",
    "data = pd.read_excel('.\\\\Dataset #1 - Regression (Brain Age Prediction)\\\\Volumetric_features.xlsx')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S.No</th>\n",
       "      <th>Left-Lateral-Ventricle</th>\n",
       "      <th>Left-Inf-Lat-Vent</th>\n",
       "      <th>Left-Cerebellum-White-Matter</th>\n",
       "      <th>Left-Cerebellum-Cortex</th>\n",
       "      <th>Left-Thalamus</th>\n",
       "      <th>Left-Caudate</th>\n",
       "      <th>Left-Putamen</th>\n",
       "      <th>Left-Pallidum</th>\n",
       "      <th>3rd-Ventricle</th>\n",
       "      <th>...</th>\n",
       "      <th>rh_superiortemporal_thickness</th>\n",
       "      <th>rh_supramarginal_thickness</th>\n",
       "      <th>rh_frontalpole_thickness</th>\n",
       "      <th>rh_temporalpole_thickness</th>\n",
       "      <th>rh_transversetemporal_thickness</th>\n",
       "      <th>rh_insula_thickness</th>\n",
       "      <th>rh_MeanThickness_thickness</th>\n",
       "      <th>BrainSegVolNotVent.2</th>\n",
       "      <th>eTIV.1</th>\n",
       "      <th>dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>884</td>\n",
       "      <td>18276.2</td>\n",
       "      <td>488.6</td>\n",
       "      <td>15488.8</td>\n",
       "      <td>60165.9</td>\n",
       "      <td>6753.3</td>\n",
       "      <td>3973.9</td>\n",
       "      <td>5154.7</td>\n",
       "      <td>2247.5</td>\n",
       "      <td>2230.6</td>\n",
       "      <td>...</td>\n",
       "      <td>2.531</td>\n",
       "      <td>2.323</td>\n",
       "      <td>2.423</td>\n",
       "      <td>3.351</td>\n",
       "      <td>2.447</td>\n",
       "      <td>2.759</td>\n",
       "      <td>2.26196</td>\n",
       "      <td>1210251</td>\n",
       "      <td>1753222.710</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2404</th>\n",
       "      <td>2405</td>\n",
       "      <td>19564.2</td>\n",
       "      <td>1550.6</td>\n",
       "      <td>11636.4</td>\n",
       "      <td>50535.2</td>\n",
       "      <td>5335.3</td>\n",
       "      <td>3155.9</td>\n",
       "      <td>3791.9</td>\n",
       "      <td>1453.2</td>\n",
       "      <td>1918.1</td>\n",
       "      <td>...</td>\n",
       "      <td>2.708</td>\n",
       "      <td>2.330</td>\n",
       "      <td>2.502</td>\n",
       "      <td>2.974</td>\n",
       "      <td>2.195</td>\n",
       "      <td>2.686</td>\n",
       "      <td>2.24386</td>\n",
       "      <td>968762</td>\n",
       "      <td>1386457.527</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1699</th>\n",
       "      <td>1700</td>\n",
       "      <td>14076.8</td>\n",
       "      <td>718.0</td>\n",
       "      <td>17377.2</td>\n",
       "      <td>54915.0</td>\n",
       "      <td>7591.1</td>\n",
       "      <td>3143.6</td>\n",
       "      <td>4072.2</td>\n",
       "      <td>1816.3</td>\n",
       "      <td>1710.6</td>\n",
       "      <td>...</td>\n",
       "      <td>2.872</td>\n",
       "      <td>2.436</td>\n",
       "      <td>2.518</td>\n",
       "      <td>3.951</td>\n",
       "      <td>2.571</td>\n",
       "      <td>2.859</td>\n",
       "      <td>2.44303</td>\n",
       "      <td>1213217</td>\n",
       "      <td>1587806.747</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3380</th>\n",
       "      <td>3381</td>\n",
       "      <td>9147.3</td>\n",
       "      <td>274.4</td>\n",
       "      <td>14968.5</td>\n",
       "      <td>55712.8</td>\n",
       "      <td>7974.4</td>\n",
       "      <td>3665.7</td>\n",
       "      <td>6010.0</td>\n",
       "      <td>2108.9</td>\n",
       "      <td>981.6</td>\n",
       "      <td>...</td>\n",
       "      <td>2.807</td>\n",
       "      <td>2.555</td>\n",
       "      <td>2.814</td>\n",
       "      <td>3.612</td>\n",
       "      <td>2.259</td>\n",
       "      <td>3.057</td>\n",
       "      <td>2.51059</td>\n",
       "      <td>1098123</td>\n",
       "      <td>1418487.708</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2284</th>\n",
       "      <td>2285</td>\n",
       "      <td>16839.5</td>\n",
       "      <td>1651.2</td>\n",
       "      <td>12847.5</td>\n",
       "      <td>41962.7</td>\n",
       "      <td>4724.7</td>\n",
       "      <td>3129.7</td>\n",
       "      <td>3110.3</td>\n",
       "      <td>1389.7</td>\n",
       "      <td>1917.6</td>\n",
       "      <td>...</td>\n",
       "      <td>2.184</td>\n",
       "      <td>2.076</td>\n",
       "      <td>2.528</td>\n",
       "      <td>2.447</td>\n",
       "      <td>2.080</td>\n",
       "      <td>2.569</td>\n",
       "      <td>2.17751</td>\n",
       "      <td>729661</td>\n",
       "      <td>1237152.881</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 140 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      S.No  Left-Lateral-Ventricle  Left-Inf-Lat-Vent  \\\n",
       "883    884                 18276.2              488.6   \n",
       "2404  2405                 19564.2             1550.6   \n",
       "1699  1700                 14076.8              718.0   \n",
       "3380  3381                  9147.3              274.4   \n",
       "2284  2285                 16839.5             1651.2   \n",
       "\n",
       "      Left-Cerebellum-White-Matter  Left-Cerebellum-Cortex  Left-Thalamus  \\\n",
       "883                        15488.8                 60165.9         6753.3   \n",
       "2404                       11636.4                 50535.2         5335.3   \n",
       "1699                       17377.2                 54915.0         7591.1   \n",
       "3380                       14968.5                 55712.8         7974.4   \n",
       "2284                       12847.5                 41962.7         4724.7   \n",
       "\n",
       "      Left-Caudate  Left-Putamen  Left-Pallidum  3rd-Ventricle  ...  \\\n",
       "883         3973.9        5154.7         2247.5         2230.6  ...   \n",
       "2404        3155.9        3791.9         1453.2         1918.1  ...   \n",
       "1699        3143.6        4072.2         1816.3         1710.6  ...   \n",
       "3380        3665.7        6010.0         2108.9          981.6  ...   \n",
       "2284        3129.7        3110.3         1389.7         1917.6  ...   \n",
       "\n",
       "      rh_superiortemporal_thickness  rh_supramarginal_thickness  \\\n",
       "883                           2.531                       2.323   \n",
       "2404                          2.708                       2.330   \n",
       "1699                          2.872                       2.436   \n",
       "3380                          2.807                       2.555   \n",
       "2284                          2.184                       2.076   \n",
       "\n",
       "      rh_frontalpole_thickness  rh_temporalpole_thickness  \\\n",
       "883                      2.423                      3.351   \n",
       "2404                     2.502                      2.974   \n",
       "1699                     2.518                      3.951   \n",
       "3380                     2.814                      3.612   \n",
       "2284                     2.528                      2.447   \n",
       "\n",
       "      rh_transversetemporal_thickness  rh_insula_thickness  \\\n",
       "883                             2.447                2.759   \n",
       "2404                            2.195                2.686   \n",
       "1699                            2.571                2.859   \n",
       "3380                            2.259                3.057   \n",
       "2284                            2.080                2.569   \n",
       "\n",
       "      rh_MeanThickness_thickness  BrainSegVolNotVent.2       eTIV.1  dataset  \n",
       "883                      2.26196               1210251  1753222.710        1  \n",
       "2404                     2.24386                968762  1386457.527        5  \n",
       "1699                     2.44303               1213217  1587806.747        4  \n",
       "3380                     2.51059               1098123  1418487.708        8  \n",
       "2284                     2.17751                729661  1237152.881        5  \n",
       "\n",
       "[5 rows x 140 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the data into training and testing sets. The output label of the data is the age\n",
    "#80% data is for training and 20% for testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.drop('Age', axis=1), data['Age'], test_size=0.2, random_state=0)\n",
    "X_train.head() # print the first 5 records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3380, 140)\n"
     ]
    }
   ],
   "source": [
    "#Number of data points and number of features for each data point\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge regression: Train\n",
      "Train Mean squared error (MSE):  54.368301773508804\n",
      "Train Root Mean squared error (RMSE):  7.373486405595985\n",
      "Train R2 Score:  0.8633872671090052\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "#Penalty\n",
    "regularization_strength = 0.5\n",
    "model_ridge = Ridge(alpha=regularization_strength)\n",
    "model_ridge.fit(X_train, y_train)\n",
    "\n",
    "# Calculate the mean squared error on train data\n",
    "y_pred = model_ridge.predict(X_train)\n",
    "mse_train = mean_squared_error(y_train, y_pred)\n",
    "rmse_train = sqrt(mse_train)\n",
    "r2_score_train = r2_score(y_train, y_pred)\n",
    "\n",
    "print('Ridge regression: Train')\n",
    "print('Train Mean squared error (MSE): ', mse_train)\n",
    "print('Train Root Mean squared error (RMSE): ', rmse_train)\n",
    "print('Train R2 Score: ', r2_score_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge regression: Test\n",
      "Test Mean squared error (MSE):  62.92796690818672\n",
      "Test Root Mean squared error (RMSE):  7.932714977117652\n",
      "R2 Score:  0.8501465123979921\n"
     ]
    }
   ],
   "source": [
    "# Calculate the test mean squared error\n",
    "y_pred = model_ridge.predict(X_test)\n",
    "mse_test = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "rmse_test = sqrt(mse_test)\n",
    "r2_score_test = r2_score(y_test, y_pred)\n",
    "\n",
    "print('Ridge regression: Test')\n",
    "print('Test Mean squared error (MSE): ', mse_test)\n",
    "print('Test Root Mean squared error (RMSE): ', rmse_test)\n",
    "print('R2 Score: ', r2_score_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge regression: Sample predictions\n",
      "  Actual labels:  [27 58 81 53 80 30 60 27 19 90 54 26 74 81 76 77 24 94 23 86] \n",
      " Predicted labels: [23.56209146 48.58179565 67.93996086 49.69091248 86.89987233 30.10547221\n",
      " 64.27179457 27.82983003 33.91326673 87.0930768  39.84087954 26.70476331\n",
      " 75.02546906 67.7584405  65.67257159 82.93490117 30.04493486 84.79482934\n",
      " 29.50680279 73.23445663]\n"
     ]
    }
   ],
   "source": [
    "print('Ridge regression: Sample predictions')\n",
    "# Make predictions on the test set\n",
    "y_pred = model_ridge.predict(X_test[:20])\n",
    "#Print first 20 actual and predicted values\n",
    "print('  Actual labels:  {} \\n Predicted labels: {}'.format(np.array(y_test[:20]), y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-Linear Regression - Neural Nets Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Reloading the data. Not necessary\n",
    "# Load the dataset\n",
    "data = pd.read_excel('.\\\\Dataset #1 - Regression (Brain Age Prediction)\\\\Volumetric_features.xlsx')\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.drop('Age', axis=1), data['Age'], test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the input data\n",
    "scaler = StandardScaler()\n",
    "\n",
    "#Scale the data\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Convert the data to tensors: train\n",
    "inputs = torch.tensor(X_train, dtype=torch.float32)\n",
    "targets = torch.tensor(y_train.values, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "inputs_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "targets_test = torch.tensor(y_test.values, dtype=torch.float32).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Four layers Neural network model\n",
    "#relu is the activation function\n",
    "class NonLinearRegressionNet(nn.Module):\n",
    "    def __init__(self, Input, Output):\n",
    "        super(NonLinearRegressionNet, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(Input, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, 16)\n",
    "        self.fc4 = nn.Linear(16, Output)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the model with input dimensions \n",
    "model = NonLinearRegressionNet(Input=140, Output=1) # Input_dimension is 140 (140 features)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "learning_rate = 0.001\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "num_epochs = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------Epoch 200/2000-------------- \n",
      " Train Loss: 308.09\n",
      "-----------Epoch 400/2000-------------- \n",
      " Train Loss: 81.62\n",
      "-----------Epoch 600/2000-------------- \n",
      " Train Loss: 39.02\n",
      "-----------Epoch 800/2000-------------- \n",
      " Train Loss: 21.73\n",
      "-----------Epoch 1000/2000-------------- \n",
      " Train Loss: 12.67\n",
      "-----------Epoch 1200/2000-------------- \n",
      " Train Loss: 8.02\n",
      "-----------Epoch 1400/2000-------------- \n",
      " Train Loss: 5.30\n",
      "-----------Epoch 1600/2000-------------- \n",
      " Train Loss: 3.76\n",
      "-----------Epoch 1800/2000-------------- \n",
      " Train Loss: 2.84\n",
      "-----------Epoch 2000/2000-------------- \n",
      " Train Loss: 2.15\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "Loss = []\n",
    "for epoch in range(num_epochs):\n",
    "    #----------------------Forward pass---------------------------\n",
    "    outputs = model(inputs)\n",
    "    loss = criterion(outputs, targets)\n",
    "    #--------------------Backward and optimize--------------------\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    Loss.append(loss)\n",
    "    # Print progress\n",
    "    if (epoch+1) % 200 == 0:\n",
    "        print('-----------Epoch {}/{}-------------- \\n Train Loss: {:.2f}'\n",
    "              .format(epoch+1, num_epochs, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    plt.plot(Loss)\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('MSE')\n",
    "    plt.legend('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nonlinear Regression: NNet: Train\n",
      "Test Mean squared error (MSE):  tensor(2.1174)\n",
      "Test Root Mean squared error (RMSE):  1.4551131890699676\n",
      "R2 Score:  0.9946796648538803\n"
     ]
    }
   ],
   "source": [
    "#------------------------Make predictions on training data-------------------------\n",
    "with torch.no_grad():\n",
    "    predicted = model(inputs)\n",
    "    mse_train = criterion(predicted, targets)\n",
    "    rmse_train = sqrt(train_loss)\n",
    "    r2_score_train = r2_score(targets, predicted)\n",
    "    \n",
    "    \n",
    "    \n",
    "    print('Nonlinear Regression: NNet: Train')\n",
    "    print('Test Mean squared error (MSE): ', mse_train)\n",
    "    print('Test Root Mean squared error (RMSE): ', rmse_train)\n",
    "    print('R2 Score: ', r2_score_train)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nonlinear Regression: NNet: Test\n",
      "Test Mean squared error (MSE):  tensor(77.7614)\n",
      "Test Root Mean squared error (RMSE):  8.818242359757964\n",
      "R2 Score:  0.8148229351275514\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    test_predictions = model(inputs_test)\n",
    "    mse_test = criterion(test_predictions, targets_test)\n",
    "    rmse_test = sqrt(mse_test)\n",
    "    r2_score_test = r2_score(targets_test, test_predictions)\n",
    "    \n",
    "    \n",
    "    \n",
    "    print('Nonlinear Regression: NNet: Test')\n",
    "    print('Test Mean squared error (MSE): ', mse_test)\n",
    "    print('Test Root Mean squared error (RMSE): ', rmse_test)\n",
    "    print('R2 Score: ', r2_score_test)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_predictions: [27 58 81 53 80 30 60 27 19 90 54 26 74 81 76 77 24 94 23 86] \n",
      "  Actual output : [28, 41, 70, 54, 89, 33, 71, 26, 26, 83, 41, 37, 67, 68, 73, 74, 25, 91, 29, 78]\n"
     ]
    }
   ],
   "source": [
    "# Print the first 20 predictions\n",
    "test_predictions =[ int(x) for x in test_predictions]\n",
    "print('test_predictions: {} \\n  Actual output : {}'.format(np.array(y_test[:20]),(test_predictions[:20])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Trees "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "# Reloading as it has been updated in the previous cells\n",
    "data = pd.read_excel('.\\\\Dataset #1 - Regression (Brain Age Prediction)\\\\Volumetric_features.xlsx')\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.drop('Age', axis=1), data['Age'], test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(max_depth=7)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "model = DecisionTreeRegressor(criterion='squared_error', splitter='best',max_depth=7)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression Trees: Train\n",
      "Mean squared error (MSE):  44.15983974606266\n",
      "Root Mean squared error (RMSE):  6.645287032631672\n",
      "R2 Score:  0.8890383514852123\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the train set\n",
    "y_pred = model.predict(X_train)\n",
    "# Calculate the mean squared error\n",
    "mse_train = mean_squared_error(y_train, y_pred)\n",
    "rmse_train = sqrt(mse_train)\n",
    "r2_score_regression_trees_train = r2_score(y_train, y_pred)\n",
    "print('Regression Trees: Train')\n",
    "print('Mean squared error (MSE): ', mse_train)\n",
    "print('Root Mean squared error (RMSE): ', rmse_train)\n",
    "print('R2 Score: ', r2_score_regression_trees_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression Trees: Test\n",
      "Mean squared error (MSE):  89.4900730911041\n",
      "Root Mean squared error (RMSE):  9.45991929622574\n",
      "R2 Score:  0.7868928519806366\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "# Calculate the mean squared error\n",
    "mse_test = mean_squared_error(y_test, y_pred)\n",
    "rmse_test = sqrt(mse_test)\n",
    "r2_score_regression_trees_test = r2_score(y_test, y_pred)\n",
    "print('Regression Trees: Test')\n",
    "print('Mean squared error (MSE): ', mse_test)\n",
    "print('Root Mean squared error (RMSE): ', rmse_test)\n",
    "print('R2 Score: ', r2_score_regression_trees_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Actual labels:  [27 58 81 53 80 30 60 27 19 90 54 26 74 81 76 77 24 94 23 86] \n",
      "Predicted labels: [32, 58, 75, 56, 79, 36, 67, 26, 26, 88, 51, 32, 72, 75, 75, 76, 26, 88, 42, 72]\n"
     ]
    }
   ],
   "source": [
    "#np.set_printoptions(precision=0)\n",
    "#making predictions\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "predictions = [int(x) for x in predictions]\n",
    "# Print the first 10 predictions\n",
    "#print(predictions[:10])\n",
    "print('  Actual labels:  {} \\nPredicted labels: {}'.format(np.array(y_test[:20]), predictions[:20]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
